{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d97b614",
   "metadata": {},
   "source": [
    "# **PROYEK PREDICTIVE ANALYTICS - RED WINE QUALITY PREDICTION** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acd1a0",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a399d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC # Contoh model lain\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style='whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818bb401",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b3184",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a72bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Understanding - Load Data\n",
    "\n",
    "file_path = './datasets/winequality-red.csv'\n",
    "try:\n",
    "    df = pd.read_csv(file_path, sep=';')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    print(\"Shape of dataset:\", df.shape)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{file_path}' not found. Please check the file path.\")\n",
    "\n",
    "if 'df' in locals():\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\nDataset Info:\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\nDescriptive Statistics:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    print(\"\\nChecking for missing values:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    print(\"\\nChecking for duplicate rows:\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    print(\"\\nUnique values in each column:\")\n",
    "    for column in df.columns:\n",
    "        print(f\"{column}: {df[column].nunique()} unique values\")\n",
    "    print(\"\\nData types of each column:\")\n",
    "    print(df.dtypes)\n",
    "else:\n",
    "    print(\"Dataset could not be loaded. Please check the file path and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431e45a3",
   "metadata": {},
   "source": [
    "### EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b82b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Understanding - EDA (Exploratory Data Analysis)\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Distribusi variabel target 'quality' sebelum transformasi\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.countplot(x='quality', data=df, palette='viridis')\n",
    "    plt.title('Distribution of Wine Quality (Original)')\n",
    "    plt.xlabel('Quality Score')\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "    # Membuat kategori biner untuk 'quality'\n",
    "    # 'good' (1) if quality > 5, else 'bad' (0)\n",
    "    df['quality_category'] = df['quality'].apply(lambda x: 1 if x > 5 else 0)\n",
    "    \n",
    "    # Simpan df asli sebelum menghapus kolom 'quality' untuk korelasi\n",
    "    df_for_corr_original = df.copy() \n",
    "    \n",
    "    df_prepared = df.drop('quality', axis=1) # Hapus kolom quality asli\n",
    "    print(\"\\n'quality_category' created and original 'quality' column dropped.\")\n",
    "\n",
    "    # Distribusi variabel target 'quality_category' setelah transformasi\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x='quality_category', data=df_prepared, palette='pastel')\n",
    "    plt.title('Distribution of Wine Quality (Binary: 0=Not Good, 1=Good)')\n",
    "    plt.xlabel('Quality Category')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks([0, 1], ['Not Good (<=5)', 'Good (>5)'])\n",
    "    plt.show()\n",
    "    print(\"\\nValue counts for 'quality_category':\")\n",
    "    class_counts_after_transform = df_prepared['quality_category'].value_counts()\n",
    "    print(class_counts_after_transform)\n",
    "    if len(class_counts_after_transform) == 2: # Pastikan ada dua kelas\n",
    "      print(\"Class imbalance ratio (Not Good : Good):\", f\"{class_counts_after_transform.get(0, 0) / class_counts_after_transform.get(1, 1):.2f}\" if class_counts_after_transform.get(1,1) != 0 else \"N/A\")\n",
    "    \n",
    "    # Cek nilai yang hilang setelah transformasi\n",
    "    print(\"\\nMissing values after transformation:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Cek duplikat setelah transformasi\n",
    "    print(\"\\nDuplicate rows after transformation:\")\n",
    "    print(df.duplicated().sum())\n",
    "    \n",
    "    # Visualisasi distribusi fitur kategorikal\n",
    "    categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    for col in categorical_features:\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.countplot(x=col, hue='quality_category', data=df, palette='pastel')\n",
    "        plt.title(f'Distribution of {col} by Quality Category')\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Count')\n",
    "        plt.legend(title='Quality Category', loc='upper right', labels=['Not Good (<=5)', 'Good (>5)'])\n",
    "        plt.show()\n",
    "\n",
    "    # Visualisasi distribusi fitur numerik (sebelum penghapusan duplikat dan scaling)\n",
    "    numerical_features = df_prepared.select_dtypes(include=np.number).columns.tolist()\n",
    "    features_for_hist = [col for col in numerical_features if col not in ['quality_category']]\n",
    "\n",
    "    if len(features_for_hist) > 0:\n",
    "        df_prepared[features_for_hist].hist(bins=20, figsize=(15, 10), layout=(-1, 3), edgecolor='black')\n",
    "        plt.suptitle('Distribution of Numerical Features (Before Deduplication & Scaling)', y=1.02)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No numerical features available for histogram plotting.\")\n",
    "\n",
    "    # Korelasi antar fitur (menggunakan df asli dengan kolom 'quality')\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix_original = df_for_corr_original.corr()\n",
    "    sns.heatmap(correlation_matrix_original, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5, annot_kws={\"size\": 8})\n",
    "    plt.title('Correlation Matrix of Features (including original quality)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Dataset 'df' not loaded. Run previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03c6919",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f4617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Data Preparation ==============\n",
    "if 'df_prepared' in locals():\n",
    "    print(\"Data preparation started.\")\n",
    "    print(f\"Number of rows before removing duplicates: {len(df_prepared)}\")\n",
    "    df_prepared.drop_duplicates(inplace=True)\n",
    "    print(f\"Number of rows after removing duplicates: {len(df_prepared)}\")\n",
    "    \n",
    "    # Cek distribusi kelas setelah penghapusan duplikat\n",
    "    print(\"\\nValue counts for 'quality_category' after deduplication:\")\n",
    "    class_counts_after_dedup = df_prepared['quality_category'].value_counts()\n",
    "    print(class_counts_after_dedup)\n",
    "    if len(class_counts_after_dedup) == 2:\n",
    "      print(\"Class imbalance ratio (Not Good : Good) after deduplication:\", f\"{class_counts_after_dedup.get(0, 0) / class_counts_after_dedup.get(1, 1):.2f}\" if class_counts_after_dedup.get(1,1) != 0 else \"N/A\")\n",
    "\n",
    "    X = df_prepared.drop('quality_category', axis=1)\n",
    "    y = df_prepared['quality_category']\n",
    "    print(\"\\nFeatures (X) and target (y) separated.\")\n",
    "    print(\"Shape of X:\", X.shape)\n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    # Pemisahan data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    print(\"Data split into training and testing sets.\")\n",
    "    print(\"Shape of X_train:\", X_train.shape)\n",
    "    print(\"Shape of X_test:\", X_test.shape)\n",
    "    print(\"Shape of y_train:\", y_train.shape)\n",
    "    print(\"Shape of y_test:\", y_test.shape)\n",
    "    print(\"\\nProportion of classes in y_train:\")\n",
    "    print(y_train.value_counts(normalize=True))\n",
    "    print(\"\\nProportion of classes in y_test:\")\n",
    "    print(y_test.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "    # Feature Scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test) # Hanya transform pada data test, tidak fit ulang\n",
    "\n",
    "    # Mengubah kembali ke DataFrame untuk kemudahan inspeks\n",
    "    X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "    print(\"\\nFirst 5 rows of scaled training data:\")\n",
    "    print(X_train_scaled_df.head())\n",
    "    print(\"\\nFirst 5 rows of scaled testing data:\")\n",
    "    print(X_test_scaled_df.head())\n",
    "    \n",
    "    # Distribusi fitur setelah scaling\n",
    "    print(\"\\nDistribution of features after scaling (Training Data):\")\n",
    "    X_train_scaled_df.hist(bins=20, figsize=(15, 10), layout=(-1, 3), edgecolor='black')\n",
    "    plt.suptitle('Distribution of Scaled Numerical Features (Training Data)', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nDistribution of features after scaling (Test Data):\")\n",
    "    X_test_scaled_df.hist(bins=20, figsize=(15, 10), layout=(-1, 3), edgecolor='black')\n",
    "    plt.suptitle('Distribution of Scaled Numerical Features (Test Data)', y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nData preparation complete.\")\n",
    "else:\n",
    "    print(\"Variable 'df_prepared' not found. Run previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ca307b",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b313a2d5",
   "metadata": {},
   "source": [
    "### Logistic Regression (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d3a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Modeling - Logistic Regression (Baseline) ==============\n",
    "\n",
    "if 'X_train_scaled' in locals():\n",
    "    log_reg = LogisticRegression(random_state=42, solver='liblinear') # liblinear baik untuk dataset kecil\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred_log_reg_train = log_reg.predict(X_train_scaled)\n",
    "    y_pred_log_reg_test = log_reg.predict(X_test_scaled)\n",
    "\n",
    "    print(\"Logistic Regression Model Trained.\")\n",
    "    print(\"--- Evaluation on Training Data (Logistic Regression) ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_log_reg_train):.4f}\")\n",
    "    print(classification_report(y_train, y_pred_log_reg_train))\n",
    "\n",
    "\n",
    "    print(\"\\n--- Evaluation on Test Data (Logistic Regression) ---\")\n",
    "    log_reg_accuracy = accuracy_score(y_test, y_pred_log_reg_test)\n",
    "    log_reg_precision = precision_score(y_test, y_pred_log_reg_test, average='weighted') # or 'binary' if positive_label is 1\n",
    "    log_reg_recall = recall_score(y_test, y_pred_log_reg_test, average='weighted')\n",
    "    log_reg_f1 = f1_score(y_test, y_pred_log_reg_test, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {log_reg_accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {log_reg_precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {log_reg_recall:.4f}\")\n",
    "    print(f\"F1-score (weighted): {log_reg_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_pred_log_reg_test))\n",
    "    print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_pred_log_reg_test))\n",
    "    \n",
    "    cm_log_reg = confusion_matrix(y_test, y_pred_log_reg_test)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm_log_reg, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=['Not Good', 'Good'], yticklabels=['Not Good', 'Good'])\n",
    "    plt.title('Confusion Matrix - Logistic Regression (Test Data)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Scaled training data not found. Run previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ce55f6",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (Default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4546a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Modeling - Random Forest Classifier (Default Parameters) ==============\n",
    "\n",
    "if 'X_train_scaled' in locals():\n",
    "    rf_clf_default = RandomForestClassifier(random_state=42)\n",
    "    rf_clf_default.fit(X_train_scaled, y_train)\n",
    "\n",
    "    y_pred_rf_default_train = rf_clf_default.predict(X_train_scaled)\n",
    "    y_pred_rf_default_test = rf_clf_default.predict(X_test_scaled)\n",
    "\n",
    "    print(\"Random Forest (Default) Model Trained.\")\n",
    "    print(\"--- Evaluation on Training Data (Random Forest Default) ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_rf_default_train):.4f}\")\n",
    "    print(classification_report(y_train, y_pred_rf_default_train))\n",
    "\n",
    "\n",
    "    print(\"\\n--- Evaluation on Test Data (Random Forest Default) ---\")\n",
    "    rf_default_accuracy = accuracy_score(y_test, y_pred_rf_default_test)\n",
    "    rf_default_precision = precision_score(y_test, y_pred_rf_default_test, average='weighted')\n",
    "    rf_default_recall = recall_score(y_test, y_pred_rf_default_test, average='weighted')\n",
    "    rf_default_f1 = f1_score(y_test, y_pred_rf_default_test, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {rf_default_accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {rf_default_precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {rf_default_recall:.4f}\")\n",
    "    print(f\"F1-score (weighted): {rf_default_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Test Data):\\n\", classification_report(y_test, y_pred_rf_default_test))\n",
    "    print(\"\\nConfusion Matrix (Test Data):\\n\", confusion_matrix(y_test, y_pred_rf_default_test))\n",
    "\n",
    "    # Feature Importances\n",
    "    importances = rf_clf_default.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    feature_importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='importance', y='feature', data=feature_importance_df, palette='mako')\n",
    "    plt.title('Feature Importances from Random Forest (Default)')\n",
    "    plt.show()\n",
    "    print(\"\\nTop 5 Feature Importances:\")\n",
    "    print(feature_importance_df.head())\n",
    "else:\n",
    "    print(\"Scaled training data not found. Run previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1606d9d3",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Modeling - Hyperparameter Tuning for Random Forest ==============\n",
    "\n",
    "# (Kriteria Tambahan)\n",
    "# Pilih model terbaik untuk dituning.\n",
    "if 'X_train_scaled' in locals():\n",
    "    print(\"Starting Hyperparameter Tuning for Random Forest...\")\n",
    "    param_grid_rf = {\n",
    "        'n_estimators': [100, 200, 300],        # Jumlah pohon dalam forest\n",
    "        'max_depth': [None, 10, 20, 30],        # Kedalaman maksimum pohon\n",
    "        'min_samples_split': [2, 5, 10],        # Jumlah sampel minimum untuk membagi node internal\n",
    "        'min_samples_leaf': [1, 2, 4],          # Jumlah sampel minimum pada leaf node\n",
    "        'max_features': ['sqrt', 'log2', None]  # Jumlah fitur untuk dipertimbangkan saat mencari split terbaik\n",
    "    }\n",
    "\n",
    "    # Menggunakan scoring='f1_weighted' karena kelas mungkin tidak seimbang\n",
    "    rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                                  param_grid=param_grid_rf,\n",
    "                                  cv=3, # Menggunakan 3-fold CV untuk kecepatan\n",
    "                                  scoring='f1_weighted', # atau 'accuracy', 'roc_auc', dll.\n",
    "                                  n_jobs=-1, # Menggunakan semua prosesor yang tersedia\n",
    "                                  verbose=1) # Untuk melihat progress\n",
    "\n",
    "    rf_grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"\\nHyperparameter Tuning Complete.\")\n",
    "    print(\"Best Parameters found for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "    # Model terbaik dari GridSearchCV\n",
    "    best_rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "    y_pred_rf_tuned_train = best_rf_clf.predict(X_train_scaled)\n",
    "    y_pred_rf_tuned_test = best_rf_clf.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "    print(\"\\n--- Evaluation on Training Data (Random Forest Tuned) ---\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_train, y_pred_rf_tuned_train):.4f}\")\n",
    "    print(classification_report(y_train, y_pred_rf_tuned_train))\n",
    "\n",
    "    print(\"\\n--- Evaluation on Test Data (Random Forest Tuned) ---\")\n",
    "    rf_tuned_accuracy = accuracy_score(y_test, y_pred_rf_tuned_test)\n",
    "    rf_tuned_precision = precision_score(y_test, y_pred_rf_tuned_test, average='weighted')\n",
    "    rf_tuned_recall = recall_score(y_test, y_pred_rf_tuned_test, average='weighted')\n",
    "    rf_tuned_f1 = f1_score(y_test, y_pred_rf_tuned_test, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {rf_tuned_accuracy:.4f}\")\n",
    "    print(f\"Precision (weighted): {rf_tuned_precision:.4f}\")\n",
    "    print(f\"Recall (weighted): {rf_tuned_recall:.4f}\")\n",
    "    print(f\"F1-score (weighted): {rf_tuned_f1:.4f}\")\n",
    "    print(\"\\nClassification Report (Test Data - Tuned):\\n\", classification_report(y_test, y_pred_rf_tuned_test))\n",
    "    print(\"\\nConfusion Matrix (Test Data - Tuned):\\n\", confusion_matrix(y_test, y_pred_rf_tuned_test))\n",
    "\n",
    "else:\n",
    "    print(\"Scaled training data not found. Run previous cells.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc92193",
   "metadata": {},
   "source": [
    "##  Evaluation - Summary of Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a69df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== Evaluation - Summary of Results ==============\n",
    "\n",
    "if 'log_reg_accuracy' in locals() and 'rf_default_accuracy' in locals() and 'rf_tuned_accuracy' in locals():\n",
    "    results_summary = pd.DataFrame({\n",
    "        'Model': ['Logistic Regression', 'Random Forest (Default)', 'Random Forest (Tuned)'],\n",
    "        'Accuracy': [log_reg_accuracy, rf_default_accuracy, rf_tuned_accuracy],\n",
    "        'Precision (Weighted)': [log_reg_precision, rf_default_precision, rf_tuned_precision],\n",
    "        'Recall (Weighted)': [log_reg_recall, rf_default_recall, rf_tuned_recall],\n",
    "        'F1-score (Weighted)': [log_reg_f1, rf_default_f1, rf_tuned_f1]\n",
    "    })\n",
    "\n",
    "    results_summary = results_summary.set_index('Model')\n",
    "    print(\"--- Summary of Model Performance on Test Data ---\")\n",
    "    print(results_summary)\n",
    "\n",
    "    # Plotting F1-scores for comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=results_summary.index, y='F1-score (Weighted)', data=results_summary.reset_index(), palette='magma')\n",
    "    plt.title('Comparison of Model F1-scores (Weighted) on Test Data')\n",
    "    plt.ylabel('F1-score (Weighted)')\n",
    "    plt.xticks(rotation=15)\n",
    "    for index, row in results_summary.reset_index().iterrows():\n",
    "        plt.text(row.name, row['F1-score (Weighted)'] + 0.01, f\"{row['F1-score (Weighted)']:.3f}\", color='black', ha=\"center\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"--- Detailed Explanation of Metrics ---\")\n",
    "    print(\"=======================================================\")\n",
    "    print(\"\"\"\n",
    "    - Akurasi (Accuracy): Proporsi total prediksi yang benar.\n",
    "      Formula: (TP + TN) / (TP + TN + FP + FN).\n",
    "      Cara kerja: Memberikan gambaran umum seberapa sering model benar. Bisa menyesatkan jika kelas tidak seimbang.\n",
    "\n",
    "    - Presisi (Precision): Dari semua yang diprediksi sebagai kelas positif, berapa banyak yang benar-benar positif.\n",
    "      Formula untuk kelas positif: TP / (TP + FP).\n",
    "      Cara kerja: Presisi tinggi berarti model jarang salah mengklasifikasikan sampel negatif sebagai positif (rendah False Positive).\n",
    "      (Weighted average memperhitungkan presisi untuk setiap kelas dan mengambil rata-ratanya berdasarkan jumlah sampel per kelas).\n",
    "\n",
    "    - Recall (Sensitivity): Dari semua yang sebenarnya kelas positif, berapa banyak yang berhasil diprediksi sebagai positif.\n",
    "      Formula untuk kelas positif: TP / (TP + FN).\n",
    "      Cara kerja: Recall tinggi berarti model mampu menemukan sebagian besar sampel positif (rendah False Negative).\n",
    "      (Weighted average memperhitungkan recall untuk setiap kelas).\n",
    "\n",
    "    - F1-score: Rata-rata harmonik dari Presisi dan Recall.\n",
    "      Formula: 2 * (Precision * Recall) / (Precision + Recall).\n",
    "      Cara kerja: Memberikan keseimbangan antara presisi dan recall, berguna terutama jika ada ketidakseimbangan kelas atau jika kedua metrik (presisi dan recall) sama pentingnya.\n",
    "      (Weighted average memperhitungkan F1-score untuk setiap kelas).\n",
    "\n",
    "    - Confusion Matrix: Tabel yang menggambarkan performa model klasifikasi. Baris merepresentasikan kelas aktual, kolom merepresentasikan kelas prediksi.\n",
    "      - TP (True Positive): Sampel positif yang diprediksi benar.\n",
    "      - TN (True Negative): Sampel negatif yang diprediksi benar.\n",
    "      - FP (False Positive): Sampel negatif yang salah diprediksi sebagai positif (Type I Error).      - FN (False Negative): Sampel positif yang salah diprediksi sebagai negatif (Type II Error).\n",
    "\n",
    "    \"\"\")\n",
    "else:\n",
    "    print(\"Model evaluation summary not generated as no models were evaluated or data was not available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
